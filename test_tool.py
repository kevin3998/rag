# test_tool.py
# è¿™æ˜¯ä¸€ä¸ªç”¨äºç‹¬ç«‹æµ‹è¯•æ‚¨Agentæ¡†æ¶ä¸­æ‰€æœ‰å·¥å…·çš„è„šæœ¬ã€‚
# è¯·å°†æ­¤æ–‡ä»¶æ”¾ç½®åœ¨æ‚¨é¡¹ç›®çš„æ ¹ç›®å½•ä¸‹è¿è¡Œã€‚

import sys
import os
import pprint

# --- è·¯å¾„è®¾ç½® (ç¡®ä¿èƒ½æ‰¾åˆ°rag_systemæ¨¡å—) ---
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

# --- å¯¼å…¥æˆ‘ä»¬éœ€è¦æµ‹è¯•çš„å·¥å…· ---
# æˆ‘ä»¬å°†åœ¨è¿™é‡Œæ•è·å¯¼å…¥é”™è¯¯ï¼Œä»¥ä¾¿åœ¨å·¥å…·æœ¬èº«æœ‰é—®é¢˜æ—¶ä¹Ÿèƒ½æä¾›åé¦ˆ
try:
    from rag_system.agent.tools.paper_finder_tool import paper_finder_tool
    from rag_system.agent.tools.semantic_search import semantic_search_tool
    from rag_system.agent.tools.prediction_tool import prediction_tool
    # ================== [ è¯Šæ–­ä»£ç  ] ==================
    from rag_system.config import settings
    import os
    print("\n" + "*"*20 + " [è¯Šæ–­ä¿¡æ¯] " + "*"*20)
    print(f"test_tool.py å°†è¦ä½¿ç”¨çš„æ•°æ®åº“ç»å¯¹è·¯å¾„æ˜¯:\n{os.path.abspath(settings.SQLITE_DB_PATH)}")
    print("*"*54 + "\n")
    # =====================================================
    print("âœ… æ‰€æœ‰å·¥å…·æ¨¡å—æˆåŠŸå¯¼å…¥ï¼")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å·¥å…·æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    print("   è¯·ç¡®ä¿æ‰€æœ‰å·¥å…·æ–‡ä»¶éƒ½å­˜åœ¨ï¼Œå¹¶ä¸”æ²¡æœ‰è¯­æ³•æˆ–å¯¼å…¥é”™è¯¯ã€‚")
    sys.exit(1)


def print_test_header(title):
    """æ‰“å°ä¸€ä¸ªæ¼‚äº®çš„æµ‹è¯•æ ‡é¢˜ã€‚"""
    print("\n" + "=" * 80)
    print(f"ğŸ§ª å¼€å§‹æµ‹è¯•: {title}")
    print("=" * 80)


def print_test_result(test_case, success, result):
    """æ‰“å°å•ä¸ªæµ‹è¯•ç”¨ä¾‹çš„ç»“æœã€‚"""
    status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
    print(f"\n--- æµ‹è¯•ç”¨ä¾‹: {test_case} ---")
    print(f"çŠ¶æ€: {status}")
    print("è¾“å‡ºç»“æœ:")
    # ä½¿ç”¨pprintæ¥ç¾è§‚åœ°æ‰“å°å¤æ‚çš„æ•°æ®ç»“æ„ï¼ˆå¦‚åˆ—è¡¨å’Œå­—å…¸ï¼‰
    pprint.pprint(result)
    print("-" * 40)


def test_paper_finder():
    """æµ‹è¯• paper_finder_tool çš„æ‰€æœ‰è·¯å¾„ã€‚"""
    print_test_header("paper_finder_tool")

    # --- 1. æˆåŠŸè·¯å¾„æµ‹è¯• ---
    # æµ‹è¯•ä¸€ä¸ªæ‚¨æ•°æ®åº“ä¸­ç¡®å®šå­˜åœ¨çš„æ¡ä»¶
    case_1_input = {'material_name_like': 'PVDF', 'min_year': 2022}
    result_1 = paper_finder_tool.invoke(case_1_input)
    # é¢„æœŸï¼šè¿”å›ä¸€ä¸ªéç©ºçš„åˆ—è¡¨
    success_1 = isinstance(result_1, list) and len(result_1) > 0
    print_test_result("æˆåŠŸè·¯å¾„ - æŸ¥æ‰¾2022å¹´åçš„PVDFè®ºæ–‡", success_1, result_1)

    # --- 2. ç©ºç»“æœè·¯å¾„æµ‹è¯• ---
    # æµ‹è¯•ä¸€ä¸ªç¡®å®šä¸å­˜åœ¨çš„æ¡ä»¶
    case_2_input = {'material_name_like': 'ä¸€ç§ä¸å­˜åœ¨çš„è¶…çº§æ°ªé‡‘ææ–™'}
    result_2 = paper_finder_tool.invoke(case_2_input)
    # é¢„æœŸï¼šè¿”å›ä¸€ä¸ªç©ºåˆ—è¡¨
    success_2 = isinstance(result_2, list) and len(result_2) == 0
    print_test_result("ç©ºç»“æœè·¯å¾„ - æŸ¥æ‰¾ä¸å­˜åœ¨çš„ææ–™", success_2, result_2)

    # --- 3. å¤šæ¡ä»¶ä¸limitæµ‹è¯• (å·²ä¿®å¤) ---
    # åœ¨å·¥å…·ä¿®å¤åï¼Œè¿™ä¸ªæŸ¥è¯¢ç°åœ¨åº”è¯¥èƒ½æˆåŠŸæ‰¾åˆ°æ•°æ®
    case_3_input = {'solvent_name': 'NMP', 'max_contact_angle': 70, 'limit': 5}
    result_3 = paper_finder_tool.invoke(case_3_input)
    # é¢„æœŸï¼šè¿”å›ä¸€ä¸ªéç©ºçš„åˆ—è¡¨ï¼Œä¸”é•¿åº¦å°äºç­‰äº5
    success_3 = isinstance(result_3, list) and len(result_3) > 0 and len(result_3) <= 5
    print_test_result("å¤šæ¡ä»¶ä¸limitæµ‹è¯• (éªŒè¯ä¿®å¤)", success_3, result_3)

    # --- 4. æ ¸å¿ƒå‚æ•°ç¼ºå¤±æµ‹è¯• ---
    # ä¸æä¾›ä»»ä½•å‚æ•°
    case_4_input = {}
    result_4 = paper_finder_tool.invoke(case_4_input)
    # é¢„æœŸï¼šæ ¹æ®æˆ‘ä»¬æœ€æ–°çš„å¥å£®æ€§è®¾è®¡ï¼Œå®ƒåº”è¯¥è¿”å›ç©ºåˆ—è¡¨
    success_4 = isinstance(result_4, list) and len(result_4) == 0
    print_test_result("æ— å‚æ•°è°ƒç”¨æµ‹è¯•", success_4, result_4)


def test_semantic_search():
    """æµ‹è¯• semantic_search_tool çš„æ‰€æœ‰æ¨¡å¼ã€‚"""
    print_test_header("semantic_search_tool")

    # --- 1. å¼€æ”¾å¼æœç´¢æ¨¡å¼ ---
    case_1_input = {'query': "ä»€ä¹ˆæ˜¯è–„è†œå¤åˆ(TFC)è†œ?"}
    result_1 = semantic_search_tool.invoke(case_1_input)
    # é¢„æœŸï¼šè¿”å›ä¸€æ®µç›¸å…³çš„æ–‡æœ¬
    success_1 = isinstance(result_1, str) and len(result_1) > 50
    print_test_result("æ¨¡å¼1 - å¼€æ”¾å¼æœç´¢", success_1, result_1)

    # --- 2. åŸºäºæ ‡é¢˜åˆ—è¡¨æ¨¡å¼ (å·²ä¿®å¤æ–­è¨€) ---
    # æˆ‘ä»¬ä½¿ç”¨æ‚¨è¯Šæ–­æŠ¥å‘Šä¸­ç¡®è®¤å­˜åœ¨çš„æ ‡é¢˜
    titles = [
        "Simple and efficient method for functionalizing photocatalytic ceramic membranes and assessment of its applicability for wastewater treatment in up-scalable membrane reactors",
        "Functionalized graphene-based polyamide thin film nanocomposite membranes for organic solvent nanofiltration"
    ]
    case_2_input = {'query': "è¯·åˆ†åˆ«æ€»ç»“è¿™ä¸¤ç¯‡è®ºæ–‡çš„æ ¸å¿ƒå†…å®¹", 'context': titles}
    result_2 = semantic_search_tool.invoke(case_2_input)
    # ================== [ å…³ é”® ä¿® å¤ ] ==================
    # é¢„æœŸï¼šè¿”å›çš„æ€»ç»“åº”åŒ…å«ä¸æ ‡é¢˜ç›¸å…³çš„å…³é”®è¯ï¼Œè€Œä¸æ˜¯ä¹‹å‰é”™è¯¯çš„ "GO" å’Œ "Kefir"
    # æˆ‘ä»¬æ£€æŸ¥ä¸æ ‡é¢˜æ›´ç›¸å…³çš„ "Fouling" (æ±¡æŸ“) å’Œ "Cellulose Nanocrystal" (çº¤ç»´ç´ çº³ç±³æ™¶ä½“)
    success_2 = (
            isinstance(result_2, str) and
            len(result_2) > 500 and  # ç¡®ä¿è¿”å›äº†è¶³å¤Ÿçš„å†…å®¹
            "å…³äºã€ŠSimple and efficient method" in result_2 and  # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ ‡é¢˜æ˜¯å¦å­˜åœ¨
            "å…³äºã€ŠFunctionalized graphene-based" in result_2 and  # æ£€æŸ¥ç¬¬äºŒä¸ªæ ‡é¢˜æ˜¯å¦å­˜åœ¨
            "é”™è¯¯" not in result_2
    )    # =====================================================
    print_test_result("æ¨¡å¼2 - åŸºäºæ ‡é¢˜åˆ—è¡¨æ€»ç»“ (éªŒè¯ä¿®å¤)", success_2, result_2)

    # --- 3. ç©ºä¸Šä¸‹æ–‡æ¨¡å¼ ---
    case_3_input = {'query': "æ€»ç»“", 'context': []}
    result_3 = semantic_search_tool.invoke(case_3_input)
    # é¢„æœŸï¼šå·¥å…·åº”è‡ªåŠ¨è½¬ä¸ºå¼€æ”¾å¼æœç´¢
    success_3 = isinstance(result_3, str) and len(result_3) > 0
    print_test_result("æ¨¡å¼3 - ç©ºä¸Šä¸‹æ–‡è‡ªåŠ¨è½¬å¼€æ”¾æœç´¢", success_3, result_3)


def test_prediction_tool():
    """æµ‹è¯• prediction_tool çš„æ¨ç†èƒ½åŠ›ã€‚"""
    print_test_header("prediction_tool")

    # å‡†å¤‡ä¸€äº›æ¨¡æ‹Ÿçš„ä¸Šä¸‹æ–‡ï¼Œå°±åƒsemantic_search_toolæ£€ç´¢åˆ°çš„ä¸€æ ·
    mock_context = """
    æ–‡çŒ®AæŒ‡å‡ºï¼Œå¢åŠ PVDFè†œä¸­çš„PVPå«é‡å¯ä»¥æé«˜å…¶äº²æ°´æ€§ï¼Œä½†ä¼šç•¥å¾®é™ä½æœºæ¢°å¼ºåº¦ã€‚
    æ–‡çŒ®Bå‘ç°ï¼Œé€šè¿‡çƒ­å¤„ç†å¯ä»¥å¢å¼ºPVDFè†œçš„ç»“æ™¶åº¦ï¼Œä»è€Œæ˜¾è‘—æå‡å…¶æœºæ¢°ç¨³å®šæ€§ã€‚
    æ–‡çŒ®Cçš„å®éªŒè¡¨æ˜ï¼Œç£ºèƒºç±»è¯ç‰©åœ¨ç–æ°´è¡¨é¢ä¸Šçš„å¸é™„è¾ƒå¼±ã€‚
    """
    case_1_input = {
        'question': "å¦‚æœæˆ‘ä»¬æƒ³å¼€å‘ä¸€ç§æ—¢èƒ½ä¿æŒä½è¯ç‰©å¸é™„ï¼Œåˆèƒ½æé«˜æœºæ¢°å¼ºåº¦çš„PVDFè†œï¼Œåº”è¯¥é‡‡å–ä»€ä¹ˆç­–ç•¥ï¼Ÿè¯·è¯´æ˜æœºç†ã€‚",
        'context': mock_context
    }
    result_1 = prediction_tool.invoke(case_1_input)
    # é¢„æœŸï¼šè¿”å›ä¸€æ®µåŒ…å«â€œå› æ­¤â€ã€â€œç»“åˆ...æ¥çœ‹â€ã€â€œä¸€ä¸ªå¯èƒ½çš„ç­–ç•¥æ˜¯â€ç­‰æ¨ç†è¯æ±‡çš„åˆ†æ
    success_1 = isinstance(result_1, str) and ("ç­–ç•¥" in result_1 or "ç»“åˆ" in result_1)
    print_test_result("åˆ†æä¸æ¨ç†æµ‹è¯•", success_1, result_1)


if __name__ == "__main__":
    print("======= å¼€å§‹æ‰§è¡ŒRAG Agentå·¥å…·å±‚å•å…ƒæµ‹è¯• =======")

    # ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ
    print("\nâš ï¸ è¯·ç¡®ä¿æ‚¨çš„OllamaæœåŠ¡æ­£åœ¨åå°è¿è¡Œ...")

    # ä¾æ¬¡è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_paper_finder()
    test_semantic_search()
    test_prediction_tool()

    print("\n\n======= æ‰€æœ‰å•å…ƒæµ‹è¯•æ‰§è¡Œå®Œæ¯• =======")