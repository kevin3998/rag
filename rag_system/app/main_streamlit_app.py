import streamlit as st
import sys
from pathlib import Path

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„ä¸­
project_root = Path(__file__).parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

# ç¡®ä¿è¿™é‡Œçš„ç±»åä¸æ‚¨ qa_chain.py æ–‡ä»¶ä¸­çš„ä¸€è‡´
from rag_system.generation.qa_chain import AdvancedQAChain
from rag_system.config import settings

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="è†œææ–™ç§‘å­¦RAGæ™ºèƒ½ä½“",
    page_icon="ğŸ§ª",
    layout="wide"
)

st.title("ğŸ§ª è†œææ–™ç§‘å­¦RAGæ™ºèƒ½ä½“")
# ä½¿ç”¨æ‚¨åœ¨Ollamaä¸­ä¸ºæ¨¡å‹å–çš„åå­—
st.caption(f"ç”±æœ¬åœ°æ¨¡å‹ 'qwen3-14b-f16:latest' å’Œ ChromaDB æä¾›æ”¯æŒ")


# --- åˆå§‹åŒ–ä¸çŠ¶æ€ç®¡ç† ---
@st.cache_resource
def load_qa_chain():
    """
    ä½¿ç”¨ç¼“å­˜åŠ è½½QAé“¾ï¼Œé¿å…æ¯æ¬¡é¡µé¢é‡è½½æ—¶éƒ½é‡æ–°åˆå§‹åŒ–æ¨¡å‹ã€‚
    """
    try:
        qa_chain_instance = AdvancedQAChain()
        return qa_chain_instance
    except Exception as e:
        st.error(f"åŠ è½½RAGç³»ç»Ÿå¤±è´¥: {e}")
        st.stop()


qa_chain = load_qa_chain()

if "messages" not in st.session_state:
    st.session_state.messages = []

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("å…³äº")
    st.info("è¿™æ˜¯ä¸€ä¸ªåŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€‚")
    st.markdown("""
    **åŠŸèƒ½:**
    - **æ—¥å¸¸å¯¹è¯**: å¯ä»¥è¿›è¡Œé€šç”¨èŠå¤©ã€‚
    - **ä¸“ä¸šé—®ç­”**: èƒ½åŸºäºæœ¬åœ°â€œè†œææ–™â€æ–‡çŒ®åº“å›ç­”ä¸“ä¸šé—®é¢˜ã€‚
    - **é¢†åŸŸè¯†åˆ«**: å½“é—®é¢˜è¶…å‡ºè†œææ–™é¢†åŸŸæ—¶ï¼Œä¼šç¤¼è²Œåœ°æ‹’ç»å›ç­”ã€‚
    """)
    if st.button("æ¸…é™¤èŠå¤©è®°å½•"):
        st.session_state.messages = []
        st.rerun()

# --- èŠå¤©ç•Œé¢ ---
# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# æ¥æ”¶æ–°è¾“å…¥
if prompt := st.chat_input("è¯·å°±æ–‡çŒ®å†…å®¹è¿›è¡Œæé—®ï¼Œæˆ–éšæ„èŠèŠ..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AIçš„å›ç­”åŒº
    with st.chat_message("assistant"):
        # ã€å…³é”®ä¼˜åŒ–ã€‘
        # 1. åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„ã€ç”¨äºæ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆçš„å ä½ç¬¦ã€‚
        answer_placeholder = st.empty()

        # 2. ä½¿ç”¨ st.status æ¥ç‹¬ç«‹æ˜¾ç¤ºâ€œæ€è€ƒè¿‡ç¨‹â€ã€‚
        with st.status("AI æ­£åœ¨æ€è€ƒ...", expanded=True) as status:
            full_response = ""

            try:
                # 3. è°ƒç”¨æµå¼å›ç­”æ¥å£
                stream = qa_chain.stream_answer(prompt)

                for chunk in stream:
                    # 4. åˆ¤æ–­æµè¾“å‡ºçš„ç±»å‹
                    if isinstance(chunk, dict) and chunk.get("type") == "status":
                        # å¦‚æœæ˜¯çŠ¶æ€ä¿¡æ¯ï¼Œæ›´æ–° status ç»„ä»¶çš„æ ‡ç­¾
                        status.update(label=chunk["message"])
                    else:
                        # å¦‚æœæ˜¯ç­”æ¡ˆæ–‡æœ¬ï¼Œç´¯åŠ å¹¶æ›´æ–°ç‹¬ç«‹çš„ç­”æ¡ˆå ä½ç¬¦
                        full_response += chunk
                        answer_placeholder.markdown(full_response + "â–Œ")

                # 5. æµç»“æŸåï¼Œæ›´æ–°æœ€ç»ˆçŠ¶æ€å¹¶æŠ˜å  status ç»„ä»¶
                status.update(label="å›ç­”ç”Ÿæˆå®Œæ¯•ï¼", state="complete", expanded=False)

            except Exception as e:
                status.update(label="å¤„ç†æ—¶å‡ºç°é”™è¯¯", state="error", expanded=False)
                st.error(f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {e}")
                full_response = f"é”™è¯¯: {e}"

        # 6. åœ¨æ‰€æœ‰æ“ä½œå®Œæˆåï¼Œæœ€ç»ˆæ›´æ–°ä¸€æ¬¡ç­”æ¡ˆå ä½ç¬¦ï¼Œç§»é™¤å…‰æ ‡
        answer_placeholder.markdown(full_response)

    # 7. å°†å®Œæ•´çš„ã€å¹²å‡€çš„æœ€ç»ˆç­”æ¡ˆå­˜å…¥èŠå¤©è®°å½•
    st.session_state.messages.append({"role": "assistant", "content": full_response})